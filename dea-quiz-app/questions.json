[
  {
    "id": "Q1",
    "section": "1",
    "sectionTitle": "Databricks Intelligence Platform",
    "question": "Databricks で**データレイアウトの決定を簡素化し、クエリ性能を最適化**する代表的な機能の組み合わせとして最も適切なのはどれ？",
    "choices": {
      "A": "Z-Ordering と VACUUM",
      "B": "Photon と DatabricksIQ",
      "C": "Auto Optimize（Optimize Write/Auto Compaction）と Liquid Clustering",
      "D": "Delta Sharing と Lakehouse Federation"
    },
    "answer": "C",
    "explanation": "Auto Optimize（Optimize Write / Auto Compaction）と Liquid Clustering の組み合わせは、\n**データレイアウト最適化の運用負荷を下げつつ、実行性能を安定化**させる定番です。\n\n- Auto Optimize: 小さすぎるファイルを抑制し、書き込み後の読み取り効率を改善\n- Liquid Clustering: パーティション設計の硬直化を避けながらクラスタリングを最適化\n- Photon などの実行エンジン最適化とも併用しやすい\n\n```sql\nOPTIMIZE sales.fct_orders;\nALTER TABLE sales.fct_orders CLUSTER BY (customer_id, order_date);\n```\n\n```python\n(df.write\n  .format(\"delta\")\n  .option(\"mergeSchema\", \"true\")\n  .mode(\"append\")\n  .saveAsTable(\"sales.fct_orders\"))\n```\n\n注意点: `VACUUM` はストレージ最適化には有効ですが、直接的なレイアウト最適化機能ではありません。",
    "references": [
      {
        "title": "Liquid clustering for Delta tables",
        "url": "https://docs.databricks.com/aws/en/delta/clustering"
      },
      {
        "title": "Optimize data file layout",
        "url": "https://docs.databricks.com/aws/en/lakehouse-architecture/performance-efficiency/best-practices#optimize-data-file-layout"
      }
    ]
  },
  {
    "id": "Q2",
    "section": "1",
    "sectionTitle": "Databricks Intelligence Platform",
    "question": "Databricks Data Intelligence Platform の価値として最も適切なのはどれ？",
    "choices": {
      "A": "単一ノードでの高速 ETL を提供する",
      "B": "データ、ガバナンス、AI/BI を同一プラットフォーム上で統合し運用できる",
      "C": "すべての処理をオンプレミスに限定する",
      "D": "CSV のみをサポートしフォーマットを統一する"
    },
    "answer": "B",
    "explanation": "Databricks Data Intelligence Platform（≒レイクハウス基盤の統合プラットフォーム）の価値は、「データ処理」だけでなく、データの“利用”に必要な要素（ガバナンス・AI/BI・協業・運用）までを同じ基盤上で一貫して回せる点にあります。したがって正解は **（データ、ガバナンス、AI/BI を同一プラットフォーム上で統合し運用できる）**です。\n\nたとえば、“統合“の具体例を示します。\n\n- 同じデータ（例：Deltaテーブル）を、ETL（エンジニア）・分析（アナリスト）・AI/ML（サイエンティスト）が共有して使う\n\n- その際に、Unity Catalog等で権限・監査・リネージを統一して管理できる（＝ガバナンスが後付けにならない）\n\n- BI領域も、AI/BIなどでプラットフォームに統合されている（“別製品に切り出さず”同じ基盤で運用）",
    "references": [
      {
        "title": "Databricks データインテリジェンスプラットフォーム（日本語）",
        "url": "https://www.databricks.com/jp/product/data-intelligence-platform"
      },
      {
        "title": "AI/BI の概念（Data Intelligence Platform との統合）",
        "url": "https://learn.microsoft.com/ja-jp/azure/databricks/ai-bi/concepts"
      },
      {
        "title": "ガバナンス機能（Unity Catalog）をワークスペースに組み込む考え方（日本語ブログ）",
        "url": "https://www.databricks.com/jp/blog/built-governance-your-databricks-workspace"
      }
    ]
  },
  {
    "id": "Q3",
    "section": "1",
    "sectionTitle": "Databricks Intelligence Platform",
    "question": "以下のうち、**同一のワークスペース内で複数チームが同じデータ資産を安全に共有**しやすくする設計として最も適切なのはどれ？",
    "choices": {
      "A": "チームごとに別ワークスペースを作り、テーブルは各自で複製する",
      "B": "Unity Catalog のカタログ/スキーマをチーム単位で分け、権限で制御する",
      "C": "すべてを個人用 DBFS に保存する",
      "D": "ジョブのクラスター名にチーム名を付ける"
    },
    "answer": "B",
    "explanation": "正解は **（Unity Catalog のカタログ/スキーマをチーム単位で分け、権限で制御する）**です。\n\n同一ワークスペース内で複数チームが同じデータ資産を安全に共有するには、「論理的な境界（カタログ/スキーマ）」と「権限（GRANT/REVOKE）」でアクセスを設計できるUnity Catalogが最も相性が良いです。Unity Catalogはメタストア上で catalog.schema.table の階層を持ち、各階層に対して権限を付与できます\n\nなぜ、UCが“共有しやすい”のか（ポイント）\n\n- 同じ実体（同じテーブル/ビュー/ボリューム）を共有しつつ、チーム単位で「見える範囲」「操作できる範囲」を権限制御できる為\n\n- UCの権限は階層に沿って整理できる為。例えば「カタログ/スキーマは見えるが、テーブルはSELECTだけ」など、最小権限での設計がしやすい\n\n- “チーム境界”を ワークスペース分割やデータ複製で作るより、単一ワークスペースの方がガバナンスを効かせた共有が実現しやすい為",
    "references": [
      {
        "title": "Unity Catalog の権限とセキュリティ保護可能なオブジェクト",
        "url": "https://learn.microsoft.com/ja-jp/azure/databricks/data-governance/unity-catalog/manage-privileges/privileges"
      },
      {
        "title": "Unity Catalog の特権の管理（GRANT/REVOKE等）",
        "url": "https://learn.microsoft.com/ja-jp/azure/databricks/data-governance/unity-catalog/manage-privileges/"
      },
      {
        "title": "Unity Catalog のベスト プラクティス（設計の推奨）",
        "url": "https://learn.microsoft.com/ja-jp/azure/databricks/data-governance/unity-catalog/best-practices"
      }
    ]
  },
  {
    "id": "Q4",
    "section": "1",
    "sectionTitle": "Databricks Intelligence Platform",
    "question": "次のうち、**短時間のアドホック分析**に最も適したコンピュート選択はどれ？",
    "choices": {
      "A": "永続的な All-purpose（対話型）クラスター",
      "B": "長時間稼働のジョブクラスターを手動で起動し続ける",
      "C": "連続稼働の DLT パイプライン専用クラスター",
      "D": "常にシングルノードクラスター"
    },
    "answer": "A",
    "explanation": "ノートブックでの対話的作業は All-purpose クラスターが基本です（用途によりサーバレス選択もあり得ますが、ここでは典型を問う）。"
  },
  {
    "id": "Q5",
    "section": "1",
    "sectionTitle": "Databricks Intelligence Platform",
    "question": "SQL 実行の高速化に寄与する Databricks の実行エンジン機能として最も適切なのはどれ？",
    "choices": {
      "A": "Photon",
      "B": "Delta Sharing",
      "C": "Repos",
      "D": "Volumes"
    },
    "answer": "A",
    "explanation": "Photon は SQL/ETL ワークロードの高速化に用いられる実行エンジンです。"
  },
  {
    "id": "Q6",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Databricks Connect の主目的として最も適切なのはどれ？",
    "choices": {
      "A": "ローカル IDE から Databricks クラスターをリモート実行対象として利用できるようにする",
      "B": "DBFS を FTP サーバとして公開する",
      "C": "Unity Catalog の監査ログを外部に転送する",
      "D": "Delta Sharing の受信設定を自動生成する"
    },
    "answer": "A",
    "explanation": "ローカル開発環境（IDE）で書いた Spark コードを Databricks 上で実行・デバッグする接続機構です。"
  },
  {
    "id": "Q7",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "ノートブックで**パラメータ化**してジョブ実行する方法として最も一般的なのはどれ？",
    "choices": {
      "A": "`%pip install` を使う",
      "B": "ウィジェット（dbutils.widgets）を使う",
      "C": "`VACUUM` を実行する",
      "D": "`DESCRIBE HISTORY` を使う"
    },
    "answer": "B",
    "explanation": "ウィジェットはジョブ実行時の入力（文字列/数値/ドロップダウン等）に使えます。"
  },
  {
    "id": "Q8",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "複数ノートブックを 1 つのリポジトリで管理し、ブランチ運用する機能はどれ？",
    "choices": {
      "A": "Repos",
      "B": "Dashboards",
      "C": "SQL Warehouse",
      "D": "Delta Sharing"
    },
    "answer": "A",
    "explanation": "Repos は Git 連携によりノートブック等の資産をバージョン管理できます。"
  },
  {
    "id": "Q9",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Auto Loader が主に解決する課題として最も適切なのはどれ？",
    "choices": {
      "A": "ストリーミングのスキーマ進化と増分ファイル取り込みを簡素化する",
      "B": "テーブルの権限付与を自動化する",
      "C": "クラスターのスポット利用を禁止する",
      "D": "SQL だけで UDF を実装する"
    },
    "answer": "A",
    "explanation": "Auto Loader は、クラウドストレージ上の新規/更新ファイルを安全に増分取り込みするための仕組みです。\n\n- ファイル検知と重複防止を自動化\n- スキーマ進化（列追加など）に追従可能\n- Structured Streaming の checkpoint と組み合わせて再実行耐性を確保\n\n```python\nstream_df = (spark.readStream\n  .format(\"cloudFiles\")\n  .option(\"cloudFiles.format\", \"json\")\n  .option(\"cloudFiles.schemaLocation\", \"dbfs:/chk/schemas/orders\")\n  .load(\"s3://raw/orders\"))\n```\n\n```sql\nCREATE TABLE IF NOT EXISTS bronze.orders\nUSING DELTA\nAS SELECT * FROM stream_tmp_view;\n```\n\n注意点: `schemaLocation` と `checkpointLocation` を混同しないこと。前者はスキーマ管理、後者は処理状態管理です。",
    "references": [
      {
        "title": "What is Auto Loader?",
        "url": "https://docs.databricks.com/aws/en/ingestion/auto-loader/"
      },
      {
        "title": "Configure Auto Loader options",
        "url": "https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/auto-loader/options"
      }
    ]
  },
  {
    "id": "Q10",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Auto Loader の**有効なソース**として最も適切なのはどれ？",
    "choices": {
      "A": "`cloudFiles` でクラウドオブジェクトストレージ（例：S3/ADLS/GCS）上のファイルを監視",
      "B": "JDBC で RDB のテーブルを監視",
      "C": "Kafka のトピックのみを監視",
      "D": "ローカル PC の `C:\\data` を監視"
    },
    "answer": "A",
    "explanation": "Auto Loader はクラウドストレージ上のファイル取り込みに最適化されています。"
  },
  {
    "id": "Q11",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Auto Loader で**増分取り込み**の状態を保持するために必須となる設定はどれ？",
    "choices": {
      "A": "`checkpointLocation`",
      "B": "`spark.sql.shuffle.partitions`",
      "C": "`spark.databricks.delta.retentionDurationCheck.enabled`",
      "D": "`spark.sql.ansi.enabled`"
    },
    "answer": "A",
    "explanation": "チェックポイントは処理済みファイルやストリーミング状態を保持します。"
  },
  {
    "id": "Q12",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Auto Loader のスキーマを永続化し、スキーマ進化を安全に扱うために用いる設定はどれ？",
    "choices": {
      "A": "`schemaLocation`",
      "B": "`mergeSchema`",
      "C": "`ZORDER BY`",
      "D": "`OPTIMIZE`"
    },
    "answer": "A",
    "explanation": "schemaLocation に推論結果や進化情報が格納され、安定運用に重要です。"
  },
  {
    "id": "Q13",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "次のうち、ノートブックでセル単位の言語を切り替える「マジックコマンド」の例として正しいのはどれ？",
    "choices": {
      "A": "`%sql`",
      "B": "`!sql`",
      "C": "`#sql`",
      "D": "`@sql`"
    },
    "answer": "A",
    "explanation": "`%sql`、`%python`、`%md` などが代表例です。"
  },
  {
    "id": "Q14",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "次のうち、Databricks の**組み込みデバッグ支援**として適切なのはどれ？",
    "choices": {
      "A": "Spark UI とジョブログ、メトリクス、イベントログの参照",
      "B": "OS のレジストリエディタ",
      "C": "ブラウザ拡張機能のみ",
      "D": "監査ログを手で grep するだけ"
    },
    "answer": "A",
    "explanation": "Spark UI（ステージ/タスク/SQL）、ドライバ/エグゼキュータログ、ジョブログなどが基本です。"
  },
  {
    "id": "Q15",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Structured Streaming を使って Auto Loader で取り込みたい。読み取りに使う典型 API はどれ？",
    "choices": {
      "A": "`spark.readStream.format(\"cloudFiles\")...`",
      "B": "`spark.read.format(\"delta\")...`",
      "C": "`dbutils.fs.mount(...)`",
      "D": "`VACUUM table`"
    },
    "answer": "A",
    "explanation": "Auto Loader を使う典型パターンは `readStream.format(\"cloudFiles\")` です。\n\n- バッチ API の `read` ではなく、継続取り込みを前提に `readStream` を利用\n- 取り込み後は `writeStream` で Delta テーブルへ保存\n- watermark を設定する場合はイベント時間列の品質に注意\n\n```python\n(spark.readStream\n  .format(\"cloudFiles\")\n  .option(\"cloudFiles.format\", \"parquet\")\n  .load(\"abfss://landing@acct.dfs.core.windows.net/events\")\n  .writeStream\n  .option(\"checkpointLocation\", \"dbfs:/chk/events\")\n  .trigger(availableNow=True)\n  .toTable(\"bronze.events\"))\n```\n\n```sql\nSELECT window(event_time, '10 minutes') AS w, count(*)\nFROM bronze.events\nGROUP BY window(event_time, '10 minutes');\n```\n\n注意点: ジョブ再実行時は同じ checkpoint を使うことで重複処理を防止できます。",
    "references": [
      {
        "title": "Use Auto Loader in Structured Streaming",
        "url": "https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/auto-loader/#incremental-ingestion-using-auto-loader-with-structured-streaming"
      },
      {
        "title": "Spark Structured Streaming guide",
        "url": "https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html"
      }
    ]
  },
  {
    "id": "Q16",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "ノートブックをジョブのタスクとして実行する際、**依存関係**として最も適切なのはどれ？",
    "choices": {
      "A": "タスク間の依存（DAG）を Workflows で設定できる",
      "B": "依存関係は OS の crontab でのみ設定する",
      "C": "依存関係は Repos のブランチ名で表現する",
      "D": "依存関係は Delta のテーブルプロパティに書く"
    },
    "answer": "A",
    "explanation": "Workflows ではタスク依存（成功時/失敗時分岐など）を構成できます。"
  },
  {
    "id": "Q17",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "次のうち、ノートブック実行時に「同じセルを複数回実行して状態が変わる」問題を減らすために有効な運用はどれ？",
    "choices": {
      "A": "ノートブックの冒頭で入力データの参照先を固定し、再実行可能な手順にする",
      "B": "すべてのセルに `display()` を置く",
      "C": "常にドライバメモリを最大化する",
      "D": "Python だけを使い SQL を禁止する"
    },
    "answer": "A",
    "explanation": "再現性（idempotency）を意識し、状態依存を減らすのが基本です。"
  },
  {
    "id": "Q18",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Auto Loader のユースケースとして最も適切なのはどれ？",
    "choices": {
      "A": "日次で増える JSON/CSV/Parquet ファイルをオブジェクトストレージから増分取り込みしてブロンズに着地",
      "B": "既存の Delta テーブルを VACUUM するだけ",
      "C": "UC のユーザー作成を自動化する",
      "D": "ノートブックの見た目を変更する"
    },
    "answer": "A",
    "explanation": "ファイル増分取り込み（ブロンズ層）での利用が典型です。"
  },
  {
    "id": "Q19",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "Databricks Connect 利用時のトラブルシューティングとして最も適切なのはどれ？",
    "choices": {
      "A": "ローカルのライブラリ版本とクラスターランタイム/DBR の互換性を確認する",
      "B": "クラスター名を短くする",
      "C": "DBFS のルートを削除する",
      "D": "常にシングルノードにする"
    },
    "answer": "A",
    "explanation": "互換性（Python/Spark/DBR）や認証設定がまず確認ポイントです。"
  },
  {
    "id": "Q20",
    "section": "2",
    "sectionTitle": "開発と取り込み",
    "question": "ストリーミング取り込みのジョブが遅い。まず確認すべき内容として適切なのはどれ？",
    "choices": {
      "A": "Spark UI でステージ/タスクのスキュー、シャッフル、I/O 待ち、バッチ処理時間を確認する",
      "B": "監査ログだけを見る",
      "C": "Repos を削除する",
      "D": "ノートブックを PDF 化する"
    },
    "answer": "A",
    "explanation": "遅延の原因は計算/シャッフル/I/O/スキュー等が多く、Spark UI が第一選択です。"
  },
  {
    "id": "Q21",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "メダリオンアーキテクチャにおける **Bronze** の主目的として最も適切なのはどれ？",
    "choices": {
      "A": "取り込みデータをできるだけ加工せず、監査可能な形で保存する",
      "B": "完全に正規化して BI 用の最終形にする",
      "C": "すべての重複を排除し集計まで完了させる",
      "D": "監査ログのみを格納する"
    },
    "answer": "A",
    "explanation": "Bronze は「生データに近い形の着地（履歴保持・再処理可能）」が基本です。"
  },
  {
    "id": "Q22",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "**Silver** の主目的として最も適切なのはどれ？",
    "choices": {
      "A": "取り込み生データをそのまま保持する",
      "B": "クリーニング・正規化・結合などの品質改善を行い、下流で使いやすくする",
      "C": "経営指標を集計しダッシュボードだけを作る",
      "D": "外部共有のために匿名化だけをする"
    },
    "answer": "B",
    "explanation": "Silver はクレンジング/整形/統合など「利用可能な形」への変換が中心です。"
  },
  {
    "id": "Q23",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "**Gold** の主目的として最も適切なのはどれ？",
    "choices": {
      "A": "生データの永続化",
      "B": "監査ログの格納",
      "C": "ビジネス利用（BI/ML）に最適化した集計・データマートを提供する",
      "D": "ファイル取り込みの増分検知"
    },
    "answer": "C",
    "explanation": "Gold は下流ユースケース向け（集計・指標・データマート）です。"
  },
  {
    "id": "Q24",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "次のうち、バッチ ETL に適したクラスター選択として最も適切なのはどれ？",
    "choices": {
      "A": "Job クラスター（タスク実行時に起動し、完了後に終了）",
      "B": "24時間稼働の All-purpose クラスターを手動管理",
      "C": "ローカル PC の Python 実行環境",
      "D": "監査ログ専用クラスター"
    },
    "answer": "A",
    "explanation": "バッチ処理は Job クラスターでコスト最適化しやすいです。"
  },
  {
    "id": "Q25",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "DLT（Delta Live Tables）の利点として最も適切なのはどれ？",
    "choices": {
      "A": "すべての処理を手動で順番に実行する必要がある",
      "B": "宣言的にパイプラインを定義し、依存関係・品質制約・運用（リトライ等）を統合できる",
      "C": "どんなデータ品質の問題も自動で修復する",
      "D": "Unity Catalog を不要にする"
    },
    "answer": "B",
    "explanation": "宣言型パイプライン、expectations、運用容易性が主要メリットです。"
  },
  {
    "id": "Q26",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "DLT の expectation（例：`CONSTRAINT valid_timestamp EXPECT (...)`）に違反したレコードの扱いで、最も典型的なのはどれ？（設定により挙動は変化し得る）",
    "choices": {
      "A": "すべてのレコードが自動的に削除される",
      "B": "違反レコードはテーブルに書き込まれ、イベントとして無効が記録される",
      "C": "直ちにワークスペースが停止する",
      "D": "UC の権限がリセットされる"
    },
    "answer": "B",
    "explanation": "期待値は「記録」「ドロップ」「失敗」などを選べますが、記録（無効としてログに残す）が基本パターンです。"
  },
  {
    "id": "Q27",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "DDL として最も適切な操作はどれ？",
    "choices": {
      "A": "`CREATE TABLE`",
      "B": "`UPDATE`",
      "C": "`MERGE`",
      "D": "`DELETE`"
    },
    "answer": "A",
    "explanation": "DDL はスキーマ/オブジェクト定義（CREATE/ALTER/DROP 等）です。"
  },
  {
    "id": "Q28",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "DML として最も適切な操作はどれ？",
    "choices": {
      "A": "`ALTER TABLE`",
      "B": "`CREATE SCHEMA`",
      "C": "`INSERT INTO`",
      "D": "`DROP TABLE`"
    },
    "answer": "C",
    "explanation": "DML はデータ操作（INSERT/UPDATE/DELETE/MERGE 等）です。"
  },
  {
    "id": "Q29",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "PySpark DataFrame で「ユーザー別に売上合計と注文回数」を計算する最も適切なパターンはどれ？",
    "choices": {
      "A": "`groupBy(\"user_id\").agg(sum(\"sales\").alias(\"total_sales\"), count(\"*\").alias(\"orders\"))`",
      "B": "`select(\"user_id\").where(\"sales\")`",
      "C": "`dropDuplicates(\"sales\")`",
      "D": "`cacheTable(\"user_id\")`"
    },
    "answer": "A",
    "explanation": "集計は `groupBy().agg()` が基本です。"
  },
  {
    "id": "Q30",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "次のうち、ウィンドウ関数を DataFrame で使う主な目的として最も適切なのはどれ？",
    "choices": {
      "A": "行ごとに独立した乱数を作る",
      "B": "パーティション内の順序を考慮した累積値、順位、移動平均との差などを計算する",
      "C": "UC 権限を付与する",
      "D": "Auto Loader のチェックポイントを設定する"
    },
    "answer": "B",
    "explanation": "Window は「グループ内の順序」を扱う計算（rank/lag/rolling 等）に使います。"
  },
  {
    "id": "Q31",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "Delta テーブルに対する `MERGE INTO` の典型用途として最も適切なのはどれ？",
    "choices": {
      "A": "取り込み済みのデータを上書きせず、参照専用にする",
      "B": "変更データ（CDC）を適用し、アップサート（更新/挿入）を行う",
      "C": "テーブルを物理削除して容量を増やす",
      "D": "クラスターを自動終了する"
    },
    "answer": "B",
    "explanation": "`MERGE` はアップサートに使われ、CDC 適用で頻出です。"
  },
  {
    "id": "Q32",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "次のうち、Delta Lake のタイムトラベルを利用する SQL として最も適切なのはどれ？",
    "choices": {
      "A": "`SELECT * FROM table VERSION AS OF 5`",
      "B": "`SELECT * FROM table CLUSTER BY (col)`",
      "C": "`SELECT * FROM table SHARE WITH other`",
      "D": "`SELECT * FROM table OPTIMIZE`"
    },
    "answer": "A",
    "explanation": "VERSION/TIMESTAMP 指定で過去スナップショット参照ができます。"
  },
  {
    "id": "Q33",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "大規模なシャッフルが発生し、特定キーにデータが偏っている（スキュー）場合の対処として適切なのはどれ？",
    "choices": {
      "A": "キーのサルティング（salt）や再パーティション戦略を検討する",
      "B": "監査ログを削除する",
      "C": "常に単一パーティションに集約する",
      "D": "Python UDF を増やす"
    },
    "answer": "A",
    "explanation": "スキューはシャッフルの偏りなので、分散の工夫（salt 等）が有効です。"
  },
  {
    "id": "Q34",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "同じ中間結果を複数回使う処理があり、再計算コストが高い。DataFrame での対処として最も適切なのはどれ？",
    "choices": {
      "A": "`cache()` / `persist()` を使う",
      "B": "`VACUUM` を実行する",
      "C": "`DROP TABLE` する",
      "D": "`GRANT USAGE` する"
    },
    "answer": "A",
    "explanation": "キャッシュは再利用により計算量を削減できます（メモリ/ディスク戦略に注意）。"
  },
  {
    "id": "Q35",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "UDF（ユーザー定義関数）を使う際の一般的な注意点として適切なのはどれ？",
    "choices": {
      "A": "常に組み込み関数より速い",
      "B": "最適化が効きにくい場合があるため、まず組み込み関数/SQL 関数を検討する",
      "C": "UC 権限を自動付与する",
      "D": "DLT では使えない"
    },
    "answer": "B",
    "explanation": "UDF は最適化（例：Catalyst/Photon）が効きにくいケースがあるため、組み込み優先が定石です。"
  },
  {
    "id": "Q36",
    "section": "3",
    "sectionTitle": "データ処理 & 変換",
    "question": "Delta テーブルで小さなファイルが大量にある場合の典型的な対策はどれ？",
    "choices": {
      "A": "`OPTIMIZE` によるファイルコンパクション",
      "B": "`DESCRIBE HISTORY` の実行回数を増やす",
      "C": "`SHOW GRANTS` を繰り返す",
      "D": "`DROP SCHEMA` する"
    },
    "answer": "A",
    "explanation": "小さなファイル問題は読み取り効率を下げるため、コンパクションが効果的です。"
  },
  {
    "id": "Q37",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "DAB（Databricks Asset Bundles）の目的として最も適切なのはどれ？",
    "choices": {
      "A": "ノートブックのセルを自動で折りたたむ",
      "B": "Databricks のリソース（ジョブ、パイプライン等）をコードとして定義し、環境ごとにデプロイ可能にする",
      "C": "DBFS を完全に廃止する",
      "D": "監査ログを暗号化する"
    },
    "answer": "B",
    "explanation": "DAB は Databricks リソースを宣言的にまとめ、再現性あるデプロイを支援します。"
  },
  {
    "id": "Q38",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "DAB と従来の「GUI でジョブを手作業作成」の違いとして最も適切なのはどれ？",
    "choices": {
      "A": "DAB はバージョン管理しにくい",
      "B": "DAB はリソース定義をファイルで管理し CI/CD に組み込みやすい",
      "C": "GUI では環境差分管理が容易",
      "D": "DAB はジョブを作れない"
    },
    "answer": "B",
    "explanation": "IaC 的に扱える点が最大の違いです。"
  },
  {
    "id": "Q39",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "Workflows で失敗したタスクを、原因修正後に**該当タスク以降を再実行**したい。最も適切なのはどれ？",
    "choices": {
      "A": "修復（Repair）実行で失敗タスク/下流のみを再実行する",
      "B": "すべてのタスクを毎回最初から実行するしかない",
      "C": "Repos を削除してから再実行する",
      "D": "UC の権限を削除してから再実行する"
    },
    "answer": "A",
    "explanation": "Repair は失敗点からの再実行を支援します（依存関係に注意）。"
  },
  {
    "id": "Q40",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "ジョブの実行ログや出力を追跡し、失敗原因を確認する基本手段として適切なのはどれ？",
    "choices": {
      "A": "Workflows の Run（実行）詳細画面でログ/出力を確認する",
      "B": "ブラウザの履歴だけを見る",
      "C": "ノートブックを PNG にする",
      "D": "DBFS を削除する"
    },
    "answer": "A",
    "explanation": "ジョブ実行の UI からタスクログ、ドライバログ、設定を辿れます。"
  },
  {
    "id": "Q41",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "Databricks 管理のサーバレス（例：サーバレス SQL/ジョブ）を使う利点として最も適切なのはどれ？",
    "choices": {
      "A": "クラスターを手動で常時チューニングする必要が増える",
      "B": "コンピュート運用の多くをプラットフォーム側に任せ、起動/スケール等を最適化できる",
      "C": "Spark UI が使えなくなる",
      "D": "Delta を使えなくなる"
    },
    "answer": "B",
    "explanation": "運用負荷軽減（管理の自動化）が大きな利点です。"
  },
  {
    "id": "Q42",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "Spark UI を使って「どこが遅いか」を特定する際、まず見るべき情報の組み合わせとして最も適切なのはどれ？",
    "choices": {
      "A": "Stage の時間、Shuffle Read/Write、Skew、Task 失敗/再試行",
      "B": "ノートブックのテーマ色",
      "C": "監査ログの保存先",
      "D": "UC のグループ名"
    },
    "answer": "A",
    "explanation": "ボトルネックはステージ/タスク/シャッフル/I/O に現れます。"
  },
  {
    "id": "Q43",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "ジョブが外部システム API を呼び出す。レート制限対策として最も適切なのはどれ？",
    "choices": {
      "A": "リトライ（指数バックオフ）と並列度の制御を組み合わせる",
      "B": "例外を握りつぶして成功扱いにする",
      "C": "常に最大並列で呼び出す",
      "D": "監査ログを無効化する"
    },
    "answer": "A",
    "explanation": "外部依存ではリトライ戦略と並列制御が基本です。"
  },
  {
    "id": "Q44",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "本番向けに「環境差分（dev/stg/prod）」を安全に扱う一般的手法として適切なのはどれ？",
    "choices": {
      "A": "すべての環境で同じ資格情報を共有する",
      "B": "環境ごとに変数/シークレット/設定を分離し、DAB などで切り替えてデプロイする",
      "C": "本番では手動コピペのみで反映する",
      "D": "監査ログを削除して差分をなくす"
    },
    "answer": "B",
    "explanation": "秘匿情報分離と環境別設定がセキュアで再現性も高いです。"
  },
  {
    "id": "Q45",
    "section": "4",
    "sectionTitle": "データパイプラインの製品化",
    "question": "「処理が失敗したが、入力データはそのまま。コード修正だけで再実行したい」場合、運用として最も適切なのはどれ？",
    "choices": {
      "A": "失敗時点の入力（ソース）を消す",
      "B": "失敗タスクを修復実行し、必要に応じて idempotent な書き込み（MERGE など）で再実行可能にする",
      "C": "監査ログを止める",
      "D": "UC を無効化する"
    },
    "answer": "B",
    "explanation": "再実行性（冪等性）と修復実行の組み合わせが実運用の基本です。"
  },
  {
    "id": "Q46",
    "section": "5",
    "sectionTitle": "データガバナンス＆品質",
    "question": "Unity Catalog における**マネージドテーブル**と**外部テーブル**の違いとして最も適切なのはどれ？",
    "choices": {
      "A": "マネージドは Databricks がストレージ上のデータ配置/ライフサイクルを管理し、外部はユーザー管理の場所を参照する",
      "B": "外部テーブルは SQL が使えない",
      "C": "マネージドテーブルは読み取り専用",
      "D": "外部テーブルは Delta 形式を使えない"
    },
    "answer": "A",
    "explanation": "所有権（データファイルの管理責任）が大きな違いです。"
  },
  {
    "id": "Q47",
    "section": "5",
    "sectionTitle": "データガバナンス＆品質",
    "question": "UC で「スキーマを利用する」ために必要になりやすい権限の組み合わせとして最も適切なのはどれ？",
    "choices": {
      "A": "`USAGE`（カタログ/スキーマ）＋対象オブジェクトへの権限（例：テーブルの `SELECT`）",
      "B": "`OWNERSHIP` がないと何もできない",
      "C": "`SELECT` だけあればスキーマ参照できる",
      "D": "`VACUUM` 権限"
    },
    "answer": "A",
    "explanation": "UC は階層に沿って `USAGE` とオブジェクト権限が必要になるのが基本です。"
  },
  {
    "id": "Q48",
    "section": "5",
    "sectionTitle": "データガバナンス＆品質",
    "question": "UC の重要なロール/概念として最も適切なのはどれ？",
    "choices": {
      "A": "Metastore 管理者（admin）やオブジェクト所有者（owner）など、管理境界を持つ役割",
      "B": "監査ログ閲覧者は存在しない",
      "C": "ジョブの所有者が UC の全権限を自動で持つ",
      "D": "クラスターの作成者が全テーブルの所有者になる"
    },
    "answer": "A",
    "explanation": "管理者・所有者・権限付与者など、ガバナンスの責務が明確です。"
  },
  {
    "id": "Q49",
    "section": "5",
    "sectionTitle": "データガバナンス＆品質",
    "question": "Unity Catalog の**リネージ（lineage）**を活用する主な目的として最も適切なのはどれ？",
    "choices": {
      "A": "ユーザーのパスワードを表示する",
      "B": "データの派生関係（上流→下流）を把握し、影響範囲分析や監査に使う",
      "C": "クラスターを停止する",
      "D": "Auto Loader のスキーマ推論を高速化する"
    },
    "answer": "B",
    "explanation": "どのデータがどこから来て、どこへ使われたかの追跡により、変更影響や品質管理が容易になります。"
  },
  {
    "id": "Q50",
    "section": "5",
    "sectionTitle": "データガバナンス＆品質",
    "question": "Delta Sharing の説明として最も適切なのはどれ？",
    "choices": {
      "A": "Databricks ワークスペース間でしか共有できない",
      "B": "共有先にデータコピーを強制しない方式で、外部システムとも共有できる（権限制御やコスト考慮が必要）",
      "C": "共有は CSV に変換してメール送付する",
      "D": "監査ログを共有するためだけの機能"
    },
    "answer": "B",
    "explanation": "共有方式（プロトコル/権限/課金/データ移動）を理解することが重要です。"
  }
]
